# SEO系列之搜索引擎工作流程

俗话说知己知彼百战百胜，为了更好的做好SEO优化，首页我们要知道搜索引擎的工作原理，才能有针对性的制定优化策略。基本上所有的搜索引擎的工作流程都是相同的：爬取网页，索引，分析，排名展出。

本文只介绍基本流程中每个环节搜索引擎主要做的事情，不做具体的原理性的展开描述，因为每个环节所涉及到的细节很多，每个环节都可以长篇大论，一片文章不可能详尽的介绍完整。后续会针对各个环节作进一步的分析。

# 浏览器的工作流程

## 1.爬取网页

搜索引擎用来爬行和访问页面的程序叫做蜘蛛/爬虫（Spider）或机器人（Robot），后文都称为爬虫。

对于爬取到的网页内容，搜索引擎会有多种算法对内容进行过滤分析，过滤掉垃圾内容，筛选出来的优质页面进入建库索引环节。

这个环节基本上就会过滤到大部分垃圾网站。

### 自动爬取
爬虫每天在网上闲逛，将爬取的网页传回搜索引擎做后续操作。

### 手动提交
我们也可以主动向搜索引擎提交链接地址，缩短爬虫发现我们网站的周期。搜索引擎一般会提供站长工具提供此功能。

### 代码自动提交

我们可以自己编写定时脚本通过搜索引擎提供的API定时提交地址，充分利用搜索引擎提供的普通收录配额，简化工作。百度现在针对主动提交收录每天都有次数限额。

## 2.索引

将优质的网页内容保存、分类，优质的网站直接进入索引库。

## 3.分析

根据一定的规则对网站进行评分，规则包括但不限于网站年龄，内容相关性，内容实用性，网站打开速度等，达到标准则予以收录。

## 4.排名展出

根据分析得到的评分对网页进行排名，用户搜索相关内容是根据排名展示搜索结果。

